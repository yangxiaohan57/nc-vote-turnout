
---
title: "Team Project 2: Estrogen Bioassay and Voting in NC"
author: "Caleb ONeel, Junbo Guan, Nikhil Bhargava, Rhayoung Park, Xiaohan Yang"
date: "10/18/20"
output:
  html_document:
    highlight: pygments
    theme: spacelab
  pdf_document: default
---

```{r setup, include=FALSE}
# DO NOT ALTER CODE IN THIS CHUNK
# The very first time you use this R markdown file, you should install each of the packages below.
# The same goes for other packages you might decide to use
# Remember that you only need to install each R package once in R (ever -- unless you change computers).
# All you need to do whenever you need to use the package again (after restarting the R session),
# is to use the library function to call the package.
# For example, type install.packages("knitr") in the console to install the knitr package. 
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(knitr)
library(dplyr)
library(ggplot2)
library(lme4)
library(pander)
library(xtable)
library(kableExtra)
library(arm)
library(pROC)
library(e1071)
library(caret)
library(tidyverse)
require(gridExtra)
library(broom)
library(sjPlot)
```

* * *

## Part I: Estrogen Bioassay

```{r}
# Enter your code for loading the data here
bio <- read.csv('../Data/bioassay.txt',sep = ' ', header = T)

bio <- bio[-c(6,819,889,2231),]
bio$protocol <- factor(bio$protocol)
bio$lab <- factor(bio$lab)
bio$uterus <- as.numeric(bio$uterus)
bio$weight <- as.numeric(bio$weight)
bio$group <- factor(bio$group)
bio$weight_bin[bio$weight<100] <- "small"
bio$weight_bin[bio$weight>=100] <- "big"
bio$weight_bin <-factor(bio$weight_bin)

history <- read.csv('../Data/history_stats_20161108.txt',sep = '\t', header = T)
voter <- read.csv('../Data/voter_stats_20161108.txt',sep = ' ', header = T)

history <- subset(history, select = -c(election_date, stats_type, update_date))
# drop the row in history where age is 'Age < 18 Or Invalid Birth Dates'
# history <- history[-382814]
aggregated_history <- aggregate(history$total_voters,
                                list(County=history$county_desc,Age=history$age,
                                     Party=history$voted_party_cd, 
                                     Race=history$race_code, Sex=history$sex_code),sum)
aggregated_voter <- aggregate(voter$total_voters,
                              list(County=voter$county_desc,Age=voter$age,Party=voter$party_cd,
                                   Race=voter$race_code, Sex=voter$sex_code),sum)
colnames(aggregated_history)[6] <- 'Total_voter_his'
colnames(aggregated_voter)[6] <- 'Total_voter_voter'

data <- left_join(aggregated_voter, aggregated_history, 
                  by = c("County"="County", "Party"="Party", "Age"="Age","Race"="Race", "Sex"="Sex"))
set.seed(0)
sample <- sample(unique(data$County), 20)
# sample <- c('CALDWELL','ORANGE','GRANVILLE','ALAMANCE','FORSYTH','SWAIN','HARNETT','YANCEY','SAMPSON','MCDOWELL',
#           'JOHNSTON','STOKES','CHOWAN','LENOIR','PITT','BEAUFORT','PERSON','ROCKINGHAM','GATES','WAKE')
subdata <- data[data$County %in% sample, ]

null_subset <- subdata[is.na(subdata$Total_voter_his),]
#data[is.na(data$ColWtCL_6),]
subdata <- subdata[!(is.na(subdata$Total_voter_his)), ]
#sum(is.na(subdata$Total_voter_his))
#sum(is.na(subdata$Total_voter_voter))

agg_subdata <- subdata[!(is.na(subdata$County) | 
                       subdata$Sex==" " | 
                      subdata$Party=="" |
                      subdata$Race=="") ,]

agg_subdata$turnout <- (agg_subdata$Total_voter_his / agg_subdata$Total_voter_voter)
agg_subdata <- agg_subdata[!(agg_subdata$turnout > 1), ]
```

### Summary

This study seeks to assess the effects estrogen has on the endocrine system. The data for this study was collected across multiple laboratories by testing estrogen agonists and antagonists on rats and monitoring the effect it had on the weight of a rat’s uterus. Our group will seek to determine the effect estrogen agonists and antagonists have on the weight of the uterus by using a multilevel linear regression model to determine the statistical effect these variables have. The lab workers conducting this study collected information on the rat’s uterus weight and body weight, whether or not the rat was given the estrogen agonist or antagonist, the protocol that documented the type of rat and delivery method, and what lab group the rats belonged to. 

### Introduction

Our statistical analysis will attempt to answer several key questions about the data presented from this study. Various laboratories were injecting rats with either an estrogen agonist which they speculated would increase the weight of the uterus, and with an estrogen antagonist which they believed would decrease the weight of the rats uterus. Our group will analyze the data they collected to examine whether or not the weight of the uterus responded to the estrogen doses the way they expected. Additionally, we want to see if the results of this study varied across the different laboratories the study was conducted in. If there are certain labs that get wildly different results, we want to make note of that. Lastly, we would like to uncover if the rats differed in their sensitivity to detect the agonist or antagonist effects based upon the protocol that was used. In this case, the protocol refers to the delivery method of the agonist or antagonist, and the age of the rat. To answer these questions, we will construct a regression model and examine if these variables or groups are statistically significant in the final output. 

### Exploratory Data Analysis (EDA)

Before beginning any analysis, we checked if there were any null values in the data. There were 4 rows containing dots in the column ‘uterus’. These rows were removed since the number of rows were minimal to significantly affect the analysis, and also there was no other information given to support any other assumptions we could have made. 

After deleting the rows, the final dataset consisted of 2,677 unique instances. In the dataset, there were 7 columns, and the response variable was defined as the weight of each rats’ uterus. There were 4 types of protocols, 11 groups, and 19 labs. The number of observations were roughly similar among groups (each group had approximately 250 observations). On the other hand, the number of observations were significantly large for Protocol A (1030 observations), followed by Protocol B (791 observations) and Protocol C (593 observations). Protocol D had the least observations (263 observations).

The distribution of the response variable was plotted. The histogram showed that the weight of the uterus weight is skewed left, and therefore a log transformation was done. The transformation did not result in a perfect normal distribution shape; it was a bimodal distribution. Although it was not perfect, it was still much better than the skewed version, and thus we decided to use the log transformed response variable. (See Appendix.)

After plotting graphs with predictors on the x-axis and the log of uterus weights on the y-axis, we decided to bin the predictor weight. As shown in the plot, there is a notable difference in the two groups of rats. One group of rats were immature and small, and the other were mature and big. A new predictor ‘weight_bin’ was made by assigning rats with weight smaller than 100mg to ‘small’ and rats with weights larger than 100mg to ‘big’.

```{r}
ggplot(bio, aes(x=weight, y=log(uterus))) + geom_point()
```

Another interesting finding was that log uterus differed by lab. Labs such as Basf and Poulenc had smaller log uterus whereas Huntingd and Citijapa had larger log uterus weights. 

```{r}
ggplot(bio,
aes(x=lab, y=log(uterus), fill=lab)) +
geom_boxplot() +
labs(title="Log uterus weight by lab",
x="Lab",y="Log uterus") + theme_classic() +
theme(legend.position="none",axis.text.x = element_text(angle = 90))
```

Moreover, the effect of ZM dose to log uterus weight seemed to differ by protocol. The slopes for ZM vs. Log uterus facet wrapped by lab also seemed to show little difference. 

```{r}
par(mfrow=c(1,2))
ggplot(bio, aes(x=ZM, y=log(uterus))) + geom_point() + facet_wrap(~protocol) + geom_smooth(method="lm",col="red3") 
ggplot(bio, aes(x=ZM, y=log(uterus))) + geom_point()  + facet_wrap(~lab) + geom_smooth(method="lm",col="red3") 
```

### Model

We selected our final model using a combination of anova f-tests to determine necessary fixed variables and AIC scores to compare models across one another. To confirm our initial hypothesis from EDA above, we varied the intercepts of our model based on lab (contstant slope) and protocol (varied slope by EE & ZM). Ultimately, we finalized a hierarchical linear model of the form: $y_{i} = \beta_{0} + \beta_{1}EE + \beta_{2}ZM + \beta_{3}weight\_bin + \gamma_{Lab} + \gamma_{(EE+ZM|Protocol)}$, where $y_{i}$ is the log of the uterus size.

```{r}
final_model_q1 <- lmer(log(uterus) ~ EE + ZM + weight_bin + (1|lab) + (EE+ZM|protocol), data=bio)
# plot(final_model_q1)
```

When examining the model, there are no clear violations of the linearity, normality, equal variance, and independence assumptions. The fixed variables in the model are also not correlated with one another.

```{r}
tab_model(final_model_q1)
```

The baseline uterus weight, on average, for the rats in the study that are large, had no dose of estrogen agonist, had no dose of estrogen antagonist, is 130.32 mg. 

After binning weight on small (less than 100 mg) and big (greater than or equal to 100 mg) based on our EDA, we included the variable in our model. Compared to a big rat, small rats, on average, have uterus that weighs 0.30 mg less.

For every additional increase in EE dosage (in mg/kg/day), the uterus weight, on average, for rats increases by 1.15 mg holding all other variables constant. For every additional increase in ZM dosage (in mg/kg/day), the uterus weight, on average, for rats decreases by 0.57 mg. Therefore, we can confirm that there is an increasing dose response trend for EE and a decreasing dose response trend for ZM holding all other variables constant.

To determine whether the dose response varies across labs, we varied the model intercepts by each lab. The estimated standard deviation 0.18 describes the variation of the log of uterus weights across different labs, holding everything else constant. Although the lab-level variance is relatively small, it’s clear that the log of uterus weights does differ by lab. From the dotplot below, ChungKor, CitFrank, Exxon, and Sumitomo are all labs that are outliers associated with larger log uterus weights, while KoreaPar, Hintingd, Basf, Poulenc, are all labs that are outliers associated with smaller log uterus weights.

To determine if the protocols differ in their sensitivity to detecting EE and ZM effects, we varied the model intercepts by each protocol (A through D) and varied their slopes by both EE and ZM. The estimated standard deviation of the coefficient, 0.06, describes the across-protocol variation attributed to the random intercepts. The estimated standard deviation of 0.02 describes the across-protocol variation attributed to the random slope, EE dosage, while the estimated standard deviation of 0.28 describes the across-protocol variation attributed to the random slope, ZM dosage. 

From the analysis above, we can tell that the protocol-level variance is small and that the log of uterus weight does not change much across different protocol measures. Additionally, we can tell that the across-protocol variation due to the random slope, EE dosage, is small, and therefore the protocol does not differ the sensitivity in detecting EE effects. This is confirmed by the dot plot below. However, the variation due to the random slope, ZM dosage, is relatively large at 0.28 compared to the random slope EE, and we can conclude that the protocol does differ in the sensitivity in detecting ZM effects. In particular, from the dot plot, protocol A has the largest effect on increasing the log of uterus weight than the other protocols. Protocol B also seems to have a decreasing effect on the log of uterus weight in comparison with the other protocols.

The estimated standard error 0.43 describes the unexplained variance in the log of uterus weights that isn’t explained by our other variables, holding everything else constant. 


```{r}
par(mfrow=c(1,2))
dotplot.ranef.mer(ranef(final_model_q1,condVar=TRUE))
```

### Conclusion

Our statistical analysis provided answers to the questions we had at the offset of the experiment. Our final model supported the hypothesis that an increase in EE (estrogen agonist) did correspond to a weight gain in the rats uterus, and that an increase in ZM dosage (estrogen antagonist) led to a decrease in the weight of the uterus. The final model also concluded that there is variation in the uterus’s weight when grouping by laboratory. Although the variation is small, it is apparent from our results that the laboratory where an experiment was conducted does lead to variance in the weight of the uterus. Finally, it appears that the protocol appears to have some slight effect on the sensitivity of the rat’s reaction to  EE and ZM. We would recommend using Protocol A which had immature female rats given oral gavage as it is the most sensitive group.

While we are confident in the results of our analysis, we do believe there are potential limitations to this study. Although this data has a substantial amount of aggregate, we were ultimately attempting to break it down by different laboratories, protocols and groups that received EE or ZM as opposed to a control group. When all these factors are taken into consideration, the number of observations we have for each subset of the data becomes a bit thin. Although we do not know if this factor ultimately came into play, there is always an increased risk that reporting or procedures vary when the different laboratories span different countries and continents. This can sometimes lead to slightly different methods in data collection and recording that may occur.

\newpage
## Part II: Voting in NC (2016 General Elections)

### Summary

This analysis aims at identifying demographic groups that voted out of those who registered in the 2016 general elections (voter turnout for demographic groups). The datasets used are voter files in North Carolina from The North Carolina State Board of Elections (NCSBE). The method of this analysis is multilevel logistic regression. The conclusions are: (1) log odds ratio of voter turnout in North Carolina does not vary by county, (2) log odds ratio for voter turnout differs between males and females, (3) log odds ratio of voter turnout also differs between males and females for different party affiliation.

### Introduction

NCSBE is the agency responsible for administering the elections process and campaign finance disclosure and compliance. They provide voter registration and actual voter data for general elections online. This analysis uses the voter files for the general elections in November 2016, and it focuses on identifying if voter turnout is associated with demographics. More specifically, this analysis is interested in exploring if age, sex, race, and party affiliation have influences on whether a registered North Carolinian would actually vote in November 2016. We are also interested in learning if these demographic features have interacting effects on one another. The method used for this analysis is multilevel/hierarchical logistic regression because voters in North Carolina are naturally grouped by county. It is reasonable to take advantage of this natural level and explore if voter turnout differs by county in the 2016 elections.


### Data

The datasets for this analysis are the registered voter dataset and the vote dataset from NCSBE. The registered voter data is a table of all registered voters in the 2016 elections. It contains 514,848 observations and 11 variables, in which the registered voters are aggregated by 10 variables (county, age, party, etc.). The voter data is a table of all actual voters in 2016. It contains 734,126 observations and 12 variables, in which voters are aggregated by 11 variables (county, age, party, voting method, etc.). We found these two tables have county, race, sex, party, and age in common, so we decided these variables to be our grouping criteria, merging conditions, and predictors. 

We needed a single table to build the model, so we decided to merge the two datasets into one table. We first aggregated these two datasets separately, both by county, age, party, sex, and race, and then left-joined actual voters into registered voters. We then sampled 20 counties out of this single table. 

During our data wrangling process, we discovered the left-joining generated more than 400 observations with actual voters as nulls, because these demographic combinations appeared in the registered voter table but not in the actual voter table. Lacking further information for these null values, we decided to drop these observations. Then we ended up with a final dataset containing 3745 observations and 7 variables.


### Exploratory Data Analysis (EDA)

Before starting the analysis, the predictors ‘age’, ‘party’, ‘race’, ‘sex’ and ‘county’ was considered as factor variable. For EDA purposes, we used turnout for the response variable. Here, turnout was defined as the number of total voters who actually voted per each group divided by the number of registered voters per each group. The histogram for the turnout showed somewhat normal distribution. (See Appendix)

The plot showing turnout rate vs. party affiliation by race revealed that there appears to be a difference in turnout rates among different party affiliation and race. For mixed race, American Indians and the unknown race group, the median turnout rate for the Libertarian party was higher than the democratic party. This was not the case for black and white voters; black libertarian and white libertarian showed slightly lower turnout rates compared to black democrats and white democrats.

```{r,include=TRUE, echo=FALSE}
ggplot(agg_subdata, aes(x=Party, y=turnout, fill=Party)) + geom_boxplot() + scale_fill_brewer(palette="Reds") +  labs(title="Party vs Turnout by Race", x="Sex",y="turnout") + theme_classic() + theme(legend.position="none") + facet_wrap(~Race)
```

The relationship between sex and turnout rate by party also appears to show a difference among these groups. Female libertarians tend to show up less compared to female democrats, but male libertarians showed up more compared to male democrats. The median turnout value for unknown libertarians was much higher than unknown democrats.  

```{r,include=TRUE, echo=FALSE}
ggplot(agg_subdata, aes(x=Party, y=turnout, fill=Party)) + geom_boxplot() + scale_fill_brewer(palette="Reds") +  labs(title="Sex vs Turnout", x="Sex",y="turnout") + theme_classic() + theme(legend.position="none") + facet_wrap(~Sex)
```
We also drew a plot to check if turnout rate varied by county. As shown in the plot below, counties such as Ashe, Hyde and Chatham showed high turnout rates whereas Hoke and Pasquotank showed relatively low turnout rates. 

```{r,include=TRUE, echo=FALSE}
ggplot(agg_subdata,
aes(x=County, y=turnout, fill=County)) +geom_boxplot() +
labs(title="Turnout rate by county", x="County",y="Turnout Rate") + theme_classic() + theme(legend.position="none",axis.text.x = element_text(angle = 90))
```

### Model
#### Model Selection

We selected our final model using ANOVA f-tests. All the predictors are categorical variables, so there is no need to center or make any transformation.

Our main goal is to identify and estimate groups that voted in the 2016 election out of those who registered. Thus, we want to keep all the predictors in our null model. Since we are curious about if the overall log odds of voting differs by county in the 2016 election, we introduced varying intercepts to our model and added county as the group variable. Furthermore, we are interested in whether the turnout rates differ between females and males for the different party affiliations, so we added the interaction term between sex and party to our null model. 
We tried to explore every possible interaction term between the four predictors. For each interaction term, we added it to the null model and did the ANOVA test. It turns out that every interaction term has a small p-value, which means every interaction term is statistically significant to our model. Since we have such a large amount of relevant data, every interaction term turned out to be statistically significant. Therefore, we decided to focus on adding interaction terms that seemed to be relevant based on our EDA and scientific significance, and included the interaction between race and party in our final model.

```{r,include=TRUE, echo=FALSE}
modelfinal <- glmer(cbind(Total_voter_his, (Total_voter_voter - Total_voter_his)) ~ Age + Sex + Race + Party + (1 | County) + Sex:Party + Race:Party, data = agg_subdata, family = binomial(link = 'logit'))
tab_model(modelfinal)
```

#### Model Assessment

The model’s binned residual plot revealed a few problems due to a trend that follows a linear pattern where when the log odds of turnout increases, the average residual decreases. Moreover, about 35% of the observations were outside the two standard error lines. Specifically, when the turnout rate was lower than 0.65, over half of the observations lie outside the 2-SE lines; when the turnout rate was higher than or equal to 0.65, over 95% of the observations lie in between the 2-SE lines.

From the binned residual plot, we can conclude our model fits the data better when the turnout rate is higher versus when it is lower. This is acceptable since the goal of this analysis is not to predict turnout rate but to identify and estimate demographic groups that voted in the 2016 election out of those who registered. One reason for what we saw may be due to a decent amount of rows with null values being removed, and most of those null values seem to be due to low turnout in that demographic group and that a large part of these null values represents 0. If that holds true, then the missing data is not at random and we bias our analysis slightly.

```{r,include=TRUE, echo=FALSE}
rawresid1 <- residuals(modelfinal,"resp")
#binned residual plots
binnedplot(x=fitted(modelfinal),y=rawresid1,xlab="Turnout rate",
          
col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
```

We also compared the AIC and BIC values for our null model and final model (include the interaction term between race and party), our final model has lower AIC and BIC values, which means our final model fits the data slightly better than the null model. 

#### Model Interpretation:

##### Fixed Effect

The intercept is 0.19, which means that a registered Asian female democrat voter within the age range of 18 to 25, the odds of turnout is 1.21.

Holding all variables constant, male voters have 28% lower turning out odds than females.
As the age of voters increased, the odd ration of turnout increased significantly. Compared to voters between 18 and 25, the odds of turnout increased by 148% and for voters between 41 and 65, the odds of turnout increased by 163% for voters over age 66. 

Among all races, American Indian or Alaska Native voters are the least active. Compared to Asian voters, they have a 36% lower odds ratio. On the other hand, white voters have the strongest will to vote, their turn out odds ratio is 12% higher than Asian voters.

Democratic voters had the strongest willingness to vote. Compared to democrats, the turnout odds ratio is 28% lower for libertarian voters and 29% lower for Republican voters.
For the interaction between party and sex, we set female democrat voters as the baseline, the odds of turning out for the polls increased by 48% for male libertarian voters. The odds of turning out for the polls increased by 31% for male republican voters.

For the interaction between race and party, Asian democrat voters were the baseline. The odds of turnout decreased by 40% when the voter was black and republican. For American Indian libertarian voters, odds of turnout increase significantly by 306%. For white Republican voters, odds of turnout increase by 62%. For mixed-race republican voters, odds of turnout increase by 65%.

##### Random Effect

The county-level standard deviation is 0.17 which describes the cross-county variation attributed to the random intercept. The counties do vary, but not much. As shown in the plot, the counties Hoke, Pasquotank, Gates, and Chatham appear to be outliers. Keeping other variables constant, the odds of turnout in Hoke, Pasquotank, and Gates is significantly lower than other counties whereas registered voters in Chatham are much more likely to show up and vote. Although the county-level variance is small, every county does differ from each other, which confirms our assumption of varying intercepts by county.

```{r,include=TRUE, echo=FALSE}
dotplot(ranef(modelfinal,condVar=TRUE))$County
```

### Conclusion
In this analysis, the associations between demographics and voter turnout was explored. The final model confirmed that voter turnout in North Carolina does not vary much by county. The intercept for counties varies by a standard deviation of 0.17, which is relatively small, so we conclude the turnout rate across counties in NC is relatively consistent. Also, voter turnout is associated with sex: holding all other variables constant, the log odds ratio for voter turnout for registered male North Carolinians are 28% less than females’. Additionally, we also explored how the voter turnout differs between females and males for different party affiliations. The model tells us that the log odds ratio for voter turnout for male democrats and republican are also less than females’ in the same parties. However, for libertarians, male’s log odds ratio for turnout is 7% larger than female.

There is a potential limitation for this analysis. As mentioned in the data cleaning phase, after merging the tables, 10% of the rows had null values. We did not have any information about these values to make further speculation or to conduct further processing. Hence, these observations were dropped before modeling. We believe this could cause limitations to our analysis. These null values might be caused from voters who moved to other counties and voted there in November 2016. It is also possible that these values are led by voters who did not vote. Dropping these observations with null values might cause bias to our model, or even lead to biased conclusions.

* * *



